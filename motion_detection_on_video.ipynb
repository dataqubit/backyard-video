{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6095e1-f173-442f-90c1-0458339b1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a07afa6-24fb-4244-b3a2-7078d6cb20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path, output_path, stats_output_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get the video frame width, height, frames per second (fps), and total frame count\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can use 'XVID', 'MJPG', etc.\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Initialize a list to store motion detection statistics\n",
    "    motion_stats = []\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read the first frame.\")\n",
    "        return\n",
    "\n",
    "    # Convert the first frame to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame2 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the current frame to grayscale\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "\n",
    "        # Compute the absolute difference between the first frame and current frame\n",
    "        diff = cv2.absdiff(gray1, gray2)\n",
    "\n",
    "        # Apply a threshold to get the binary image\n",
    "        _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Dilate the threshold image to fill in holes, then find contours\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw the contours on the frame and collect statistics\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:\n",
    "                continue  # Ignore small contours\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate the timestamp of the current frame\n",
    "            frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            timestamp = frame_number / fps\n",
    "\n",
    "            # Collect the motion detection event statistics\n",
    "            motion_stats.append({\n",
    "                \"timestamp\": timestamp,\n",
    "                \"rectangle_size\": w * h\n",
    "            })\n",
    "\n",
    "        # Write the frame into the output video\n",
    "        out.write(frame2)\n",
    "\n",
    "        # Update the first frame\n",
    "        gray1 = gray2\n",
    "\n",
    "    # Release the video capture and writer objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Save the motion statistics to a CSV file\n",
    "    motion_stats_df = pd.DataFrame(motion_stats)\n",
    "    motion_stats_df.to_csv(stats_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c5c87e-d09a-49ed-8e82-ffe9c32a4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"videos/raw_2024-07-15_21-04-35.mp4\"  # Replace with your video file path\n",
    "output_path = video_path.replace(\"raw\", \"motion_raw\")\n",
    "stats_output_path = video_path.replace(\n",
    "    \"videos/\", \"motion_stats/motion_stats_\").replace(\".mp4\", \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3856aa9-80de-4625-a1f8-457edd4bd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(video_path, output_path, stats_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca350c2a-e84b-4304-b037-719c06d72538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
